

1.  这里用2d to 3d 的代码，生成了voting的点云 （已转换到nerf坐标系下）
    具体的实验，可以看飞书上的笔记
    ##########
        2d to 3d (m2f 和 fusion label投影到3d上)，用的gt点云，（b1和b2比较稀疏，其他两个还可以）
        /data/yuqi/code/GP-NeRF-semantic/bash_rebuttal/4_pointcloud_method/1015_3d_get_2d_b1.sh
    ##########
        存储在 /data/yuqi/code/GP-NeRF-semantic/zyq_rebuttal_4/2d_to_3d 下

    暂时还没投影到2d，等第三步一起出来再说


2.  用RandLaNet b1和b2改用dji点云（更密集，因为要投影得到2d的指标），yingrenshi和campus仍用gt点云   (到1月29号晚上10点，campus点云还没跑完)
    

    #######
    这个处理步骤：
    a. 用 Urban3D-2021-2nd/bash_rebuttal/prepare_b1.sh 处理数据，进行分割 （得到dji坐标系下的点云）
    b. 然后通过 Urban3D-2021-2nd/bash_rebuttal/transformer_label_b1.sh ， 得到nerf坐标系下的点云
    c. 然后投影到2d上   /data/yuqi/code/GP-NeRF-semantic/bash_rebuttal/4_pointcloud_method/1015_3d_get_2d_2project_b1_dji.sh
    d. 得到的文件路径   /data/yuqi/code/GP-NeRF-semantic/zyq_rebuttal_4/RandLaNet

    #######

    已完成 b1   b2
    未完成 yingrenshi campus


3. 现在考虑用相同的点云进行投影，得到2d指标

    所以在b1 和 b2 的dji点云上跑 2d to 3d 
    

